Hyperparameter Optimization Summary
=================================

Study Name: dqn_hyperparameter_optimization
Number of Trials: 50
Number of Pareto Optimal Trials: 3

Pareto Optimal Solutions:
------------------------

Trial 16:
Goal Reached Proportion: 0.197
Lava Proportion: 0.362
Parameters:
  model.buffer_size: 295370
  model.learning_starts: 427010
  model.batch_size: 471
  model.learning_rate: 0.00038759278114732437
  model.gamma: 0.6855311144783164
  model.train_freq: 129
  model.target_update_interval: 18729
  model.exploration_fraction: 0.4374206116844282
  model.exploration_final_eps: 0.019883990425808396

Trial 26:
Goal Reached Proportion: 0.525
Lava Proportion: 0.367
Parameters:
  model.buffer_size: 113833
  model.learning_starts: 67765
  model.batch_size: 509
  model.learning_rate: 0.0002247909397089375
  model.gamma: 0.5806128458534566
  model.train_freq: 117
  model.target_update_interval: 25197
  model.exploration_fraction: 0.7115027315774087
  model.exploration_final_eps: 0.017708480023885826

Trial 35:
Goal Reached Proportion: 0.241
Lava Proportion: 0.365
Parameters:
  model.buffer_size: 428407
  model.learning_starts: 316654
  model.batch_size: 83
  model.learning_rate: 0.00013221061477149669
  model.gamma: 0.6941234234708479
  model.train_freq: 97
  model.target_update_interval: 29796
  model.exploration_fraction: 0.8559677829098732
  model.exploration_final_eps: 0.09838767414432652
